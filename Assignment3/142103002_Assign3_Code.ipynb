{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJbc2zvMWpMO"
      },
      "outputs": [],
      "source": [
        "# !pip install sklearn_crfsuite\n",
        "\n",
        "# Import necessary libraries\n",
        "import nltk\n",
        "import string\n",
        "import pycrfsuite\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "# Download the Brown Corpus from NLTK\n",
        "nltk.download(\"brown\")\n",
        "BrownCorpus = nltk.corpus.brown.tagged_sents(categories=\"news\")\n",
        "\n",
        "\n",
        "# Define a function to extract features for each word in a sentence\n",
        "def word_features(sentence, i):\n",
        "    word = sentence[i][0]\n",
        "    special_chars = set(string.punctuation)\n",
        "    features = {\n",
        "        \"word\": word,\n",
        "        \"upper_capitalized\": word[0].upper() == word[0],\n",
        "        \"check_first_word\": i == 0,\n",
        "        \"check_last_word\": i == len(sentence) - 1,\n",
        "        \"all_uppercase\": word.upper() == word,\n",
        "        \"all_lowercase\": word.lower() == word,\n",
        "        \"prev_word\": \"\" if i == 0 else sentence[i - 1][0],\n",
        "        \"next_word\": \"\" if i == len(sentence) - 1 else sentence[i + 1][0],\n",
        "        \"prefix-1\": word[0],\n",
        "        \"first_2words\": word[:2],\n",
        "        \"last_2words\": word[-2:],\n",
        "        \"suffix-1\": word[-1],\n",
        "        \"check_number\": word.isdigit(),\n",
        "        \"check_capitals\": word[1:].lower() != word[1:],\n",
        "        \"has_special_chars\": any(char in special_chars for char in word),\n",
        "    }\n",
        "    return features\n",
        "\n",
        "\n",
        "# Initialize lists to store features and labels for training\n",
        "word = []\n",
        "label = []\n",
        "\n",
        "# Extract features and labels from the Brown Corpus\n",
        "for s in BrownCorpus:\n",
        "    word_sentence = []\n",
        "    label_sentence = []\n",
        "    for n in range(len(s)):\n",
        "        word_sentence.append(word_features(s, n))\n",
        "        label_sentence.append(s[n][1])\n",
        "    word.append(word_sentence)\n",
        "    label.append(label_sentence)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "split = int(0.8 * len(word))\n",
        "word_train = word[:split]\n",
        "label_train = label[:split]\n",
        "word_test = word[split:]\n",
        "label_test = label[split:]\n",
        "\n",
        "# Train a CRF model using sklearn_crfsuite\n",
        "crf_values = sklearn_crfsuite.CRF(\n",
        "    algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=10, all_possible_transitions=True\n",
        ")\n",
        "crf_values.fit(word_train, label_train)\n",
        "\n",
        "# Make predictions on the test set and print accuracy\n",
        "label_pred = crf_values.predict(word_test)\n",
        "print(metrics.flat_accuracy_score(label_test, label_pred))\n",
        "\n",
        "# Train a CRF model using pycrfsuite\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "for x, y in zip(word_train, label_train):\n",
        "    trainer.append(x, y)\n",
        "trainer.set_params(\n",
        "    {\"c1\": 1.0, \"c2\": 1e-3, \"max_iterations\": 50, \"feature.possible_transitions\": True}\n",
        ")\n",
        "trainer.train(\"pos.crfsuite\")\n",
        "\n",
        "\n",
        "# Define a function to tag a sentence using the trained model\n",
        "def tag_sentence(tagger, sentence):\n",
        "    features = [word_features(sentence, i) for i in range(len(sentence))]\n",
        "    return tagger.tag(features)\n",
        "\n",
        "\n",
        "# Read input sentences from a file\n",
        "with open(\"142103002_Assign3_input.txt\", \"r\") as input_file:\n",
        "    input_sentences = [line.strip().split() for line in input_file]\n",
        "\n",
        "# Load the trained model and tag each input sentence\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open(\"pos.crfsuite\")\n",
        "\n",
        "# tagged results to an output file\n",
        "with open(\"142103002_Assign3_output.txt\", \"w\") as output_file:\n",
        "    for sentence in input_sentences:\n",
        "        tags = tag_sentence(tagger, sentence)\n",
        "        result = list(zip(sentence, tags))\n",
        "        output_file.write(str(result) + \"\\n\")\n",
        "        print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
